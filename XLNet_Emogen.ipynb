{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNet_Emogen.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7F6QNvB_XgZ",
        "outputId": "9a5df292-250e-4e42-db93-00e994b5a095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.12\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.10.0+cu111\n",
            "transformers: 4.14.1\n",
            "\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark\n",
        "!pip install -qq transformers\n",
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece\n",
        "import transformers\n",
        "from transformers import XLNetModel, XLNetTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "RANDOM_SEED = 69  \n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbudm7jWLJ9y",
        "outputId": "8915b9fd-3173-4a32-d2f3-5be9ad8c6dd6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_dataset = pd.read_csv(\"go_emotions_dataset.csv\")\n",
        "bad_indices = emoji_dataset.query('example_very_unclear == False').index\n",
        "emoji_updated1 = emoji_dataset.iloc[bad_indices,:].drop(columns = ['example_very_unclear', 'id'])\n",
        "emo_dict = {'Sentences' : emoji_updated1.iloc[:,0].to_numpy(), 'Emotions': emoji_updated1.iloc[:,1:].idxmax(1).to_numpy()}\n",
        "emoji_updated2 = pd.DataFrame(emo_dict)"
      ],
      "metadata": {
        "id": "MJYobxrkLw0r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 35, 12\n",
        "sns.countplot(emoji_updated2.Emotions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "MLStMuc6MGg7",
        "outputId": "ea3a0e2f-7d3b-4ffc-f404-1f411d29a2f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f643c5666d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2520x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_updated2.groupby('Emotions').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "IEp0tTpCMJ9p",
        "outputId": "6a833593-7634-40db-88cc-8ee0821951d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-50217c48-2eed-4e0c-8cde-728b18ab31ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotions</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>admiration</th>\n",
              "      <td>17131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amusement</th>\n",
              "      <td>8862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>7956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annoyance</th>\n",
              "      <td>11929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>approval</th>\n",
              "      <td>15530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caring</th>\n",
              "      <td>5147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confusion</th>\n",
              "      <td>6600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>curiosity</th>\n",
              "      <td>7707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>desire</th>\n",
              "      <td>3002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disappointment</th>\n",
              "      <td>6769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disapproval</th>\n",
              "      <td>8917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>3420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embarrassment</th>\n",
              "      <td>1720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>excitement</th>\n",
              "      <td>4375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>2514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gratitude</th>\n",
              "      <td>8437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grief</th>\n",
              "      <td>494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>5120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>5310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nervousness</th>\n",
              "      <td>946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>55298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>optimism</th>\n",
              "      <td>4994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pride</th>\n",
              "      <td>714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>realization</th>\n",
              "      <td>5125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relief</th>\n",
              "      <td>814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>remorse</th>\n",
              "      <td>1648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>3863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>3472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50217c48-2eed-4e0c-8cde-728b18ab31ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50217c48-2eed-4e0c-8cde-728b18ab31ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50217c48-2eed-4e0c-8cde-728b18ab31ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                Sentences\n",
              "Emotions                 \n",
              "admiration          17131\n",
              "amusement            8862\n",
              "anger                7956\n",
              "annoyance           11929\n",
              "approval            15530\n",
              "caring               5147\n",
              "confusion            6600\n",
              "curiosity            7707\n",
              "desire               3002\n",
              "disappointment       6769\n",
              "disapproval          8917\n",
              "disgust              3420\n",
              "embarrassment        1720\n",
              "excitement           4375\n",
              "fear                 2514\n",
              "gratitude            8437\n",
              "grief                 494\n",
              "joy                  5120\n",
              "love                 5310\n",
              "nervousness           946\n",
              "neutral             55298\n",
              "optimism             4994\n",
              "pride                 714\n",
              "realization          5125\n",
              "relief                814\n",
              "remorse              1648\n",
              "sadness              3863\n",
              "surprise             3472"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = emoji_updated2.Emotions.unique()\n",
        "values = np.arange(28)\n",
        "dictionary_emo_val = dict(zip(values, class_names))\n",
        "dictionary_val_emo = dict(zip(class_names, values))\n",
        "emoji_updated3 = emoji_updated2.replace(dictionary_val_emo)"
      ],
      "metadata": {
        "id": "cm_GcWZpNlDR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n",
        "tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "MAX_LEN = 150"
      ],
      "metadata": {
        "id": "antKLpEpOPPh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmojiDataset(Dataset):\n",
        "\n",
        "  def __init__(self, sentences, targets, tokenizer, max_len):\n",
        "    self.sentences = sentences\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.sentences[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "      truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = EmojiDataset(\n",
        "    sentences=df.Sentences.to_numpy(),\n",
        "    targets=df.Emotions.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.XLNet = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.1)\n",
        "    self.out = nn.Linear(self.XLNet.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    pooled_output = self.XLNet(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    output = self.drop(pooled_output[0])\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "Jo5JD25pSZkg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(emoji_updated3, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(emoji_updated3, test_size=0.5, random_state=RANDOM_SEED)\n",
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EthArmn4T2xw",
        "outputId": "8c5dd17a-970b-4df7-e4e6-750ed273021c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((187032, 2), (103907, 2), (103907, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "zvzl2GcXUAkW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XLNet_model = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "XLNet_model.config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOk3WQNZUhmQ",
        "outputId": "3d3b8266-f618-4fdf-c106-898433519c9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)\n",
        "EPOCHS = 20\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False, eps = 1e-6)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMclf1ohUis2",
        "outputId": "aacb1de4-5968-4472-9b0a-db6e22207603"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    outputs = outputs.to(device)\n",
        "    _, preds = torch.max(outputs[:,149,:], dim=1)\n",
        "    #one_hot = torch.zeros(64, 28).type(torch.LongTensor).to(device)\n",
        "    #one_hot[torch.arange(64), targets] = 1\n",
        "    #ont_hot = one_hot.to(device)\n",
        "    loss = loss_fn(outputs[:,149,:], targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs[:,149,:], dim=1)\n",
        "      #one_hot = torch.zeros(64, 28).type(torch.LongTensor).to(device)\n",
        "      #one_hot[torch.arange(64), targets] = 1\n",
        "      #ont_hot = one_hot.to(device)\n",
        "      loss = loss_fn(outputs[:,149,:], targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "DMO26IBRXJbH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  ) \n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzQSrbIrXZwm",
        "outputId": "adea91fa-9225-48da-b9c4-4e7b5a837dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "Train loss 2.0454094597545343 accuracy 0.40135377903246505\n",
            "Val   loss 1.8179703087642276 accuracy 0.4427516914163627\n",
            "\n",
            "Epoch 2/20\n",
            "----------\n",
            "Train loss 1.864765699864902 accuracy 0.4356046024209761\n",
            "Val   loss 1.7314588404054125 accuracy 0.46104689770660306\n",
            "\n",
            "Epoch 3/20\n",
            "----------\n",
            "Train loss 1.7944771960056525 accuracy 0.4493936866418581\n",
            "Val   loss 1.6646815131744142 accuracy 0.47600257922950334\n",
            "\n",
            "Epoch 4/20\n",
            "----------\n",
            "Train loss 1.7387731066722394 accuracy 0.46145044698233456\n",
            "Val   loss 1.592826038085181 accuracy 0.49229599545747643\n",
            "\n",
            "Epoch 5/20\n",
            "----------\n",
            "Train loss 1.6876348528680922 accuracy 0.4715984430471791\n",
            "Val   loss 1.5374547861920203 accuracy 0.5045473355981792\n",
            "\n",
            "Epoch 6/20\n",
            "----------\n",
            "Train loss 1.6416173835262386 accuracy 0.48163415886051586\n",
            "Val   loss 1.483295968527277 accuracy 0.5168852916550377\n",
            "\n",
            "Epoch 7/20\n",
            "----------\n",
            "Train loss 1.5974820929359907 accuracy 0.4891622823901792\n",
            "Val   loss 1.427077535705026 accuracy 0.5289537759727448\n",
            "\n",
            "Epoch 8/20\n",
            "----------\n",
            "Train loss 1.5565216671592603 accuracy 0.49823559604773515\n",
            "Val   loss 1.3754426279458507 accuracy 0.5413013560202874\n",
            "\n",
            "Epoch 9/20\n",
            "----------\n",
            "Train loss 1.5177562477610675 accuracy 0.5062663073698619\n",
            "Val   loss 1.3370352370912217 accuracy 0.5483942371543785\n",
            "\n",
            "Epoch 10/20\n",
            "----------\n",
            "Train loss 1.4859333717778167 accuracy 0.5122171606997733\n",
            "Val   loss 1.3032600293532381 accuracy 0.554457351285284\n",
            "\n",
            "Epoch 11/20\n",
            "----------\n",
            "Train loss 1.4527920245349386 accuracy 0.5190288292912443\n",
            "Val   loss 1.2646795356361737 accuracy 0.5612230167361199\n",
            "\n",
            "Epoch 12/20\n",
            "----------\n",
            "Train loss 1.4239081378632361 accuracy 0.5239103468925104\n",
            "Val   loss 1.2361507092790651 accuracy 0.5644951735686721\n",
            "\n",
            "Epoch 13/20\n",
            "----------\n",
            "Train loss 1.3978903349890432 accuracy 0.5294388126096069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DzxpMwhNbsJ",
        "outputId": "1d215424-d3e4-4e45-b465-a0f69a186220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnJnS-lbNeoI",
        "outputId": "efb9c8a5-aecd-4697-ceee-6cb3246e1470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47029555275390494"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "T5_DmnnOPXrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "id": "5llXMqpXPfi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMlYbq5KPhJv",
        "outputId": "03425eb3-e896-4b74-a1be-cdb364e76e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "       sadness       0.37      0.38      0.38      1990\n",
            "       neutral       0.61      0.52      0.56     27509\n",
            "          love       0.51      0.71      0.60      2632\n",
            "     gratitude       0.72      0.69      0.71      4190\n",
            "   disapproval       0.36      0.40      0.38      4491\n",
            "     amusement       0.58      0.71      0.64      4459\n",
            "disappointment       0.29      0.31      0.30      3367\n",
            "    admiration       0.55      0.67      0.61      8536\n",
            "   realization       0.28      0.23      0.25      2578\n",
            "     annoyance       0.33      0.25      0.28      5945\n",
            "     confusion       0.40      0.40      0.40      3349\n",
            "      optimism       0.41      0.36      0.39      2507\n",
            "     curiosity       0.46      0.44      0.45      3799\n",
            "    excitement       0.40      0.29      0.34      2196\n",
            "        caring       0.37      0.43      0.40      2585\n",
            "       disgust       0.33      0.36      0.35      1683\n",
            "       remorse       0.45      0.45      0.45       814\n",
            "           joy       0.35      0.41      0.38      2552\n",
            "      approval       0.37      0.36      0.37      7803\n",
            " embarrassment       0.34      0.29      0.31       873\n",
            "      surprise       0.39      0.44      0.41      1761\n",
            "         anger       0.38      0.55      0.45      4005\n",
            "         grief       0.26      0.42      0.32       255\n",
            "         pride       0.25      0.20      0.22       363\n",
            "        desire       0.39      0.40      0.39      1481\n",
            "        relief       0.28      0.20      0.24       414\n",
            "          fear       0.45      0.54      0.49      1272\n",
            "   nervousness       0.32      0.16      0.21       498\n",
            "\n",
            "      accuracy                           0.47    103907\n",
            "     macro avg       0.40      0.41      0.40    103907\n",
            "  weighted avg       0.47      0.47      0.47    103907\n",
            "\n"
          ]
        }
      ]
    }
  ]
}